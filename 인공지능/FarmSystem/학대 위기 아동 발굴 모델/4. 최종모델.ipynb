{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8dd29-3d48-46c9-8a2c-68fa8b33ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from pycaret.classification import * #3.3.0\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #1.4.2\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# XGBoost 모델 학습\n",
    "xgb_clf = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# 결과 평가\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 트리 개수, 트리 깊이, 학습률 변경\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=300, # 기본값 100 (트리 개수)\n",
    "    max_depth=5,            # 기본값 3 (트리 깊이)\n",
    "    learning_rate=0.05, # 기본값 0.1\n",
    "    subsample=1.0, # 전체 데이터 사용\n",
    "    colsample_bytree=1.0 # 전체 feature 사용\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 훈련, 테스트 데이터로 예측\n",
    "y_train_pred = xgb_clf.predict(X_train)\n",
    "y_test_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# 성능 평가 (훈련 데이터, 테스트 데이터)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "# report = classification_report(y_test, y_pred) #정밀도, 재현율, F1-점수를 포함한 성능 지표\n",
    "\n",
    "print(\"max_depth 튜닝 결과\")\n",
    "print(f\"Train Accuracy= {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# 학습 곡선 생성 (X와 y는 이전에 TF-IDF로 변환한 데이터와 타겟)\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    xgb_clf, X, y, train_sizes=[0.1, 0.33, 0.55, 0.78, 1.0], cv=5, scoring='accuracy')\n",
    "\n",
    "# 학습 및 검증 정확도의 평균 계산\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "valid_mean = np.mean(valid_scores, axis=1)\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "plt.plot(train_sizes, train_mean, label='Training Accuracy', marker='o')\n",
    "plt.plot(train_sizes, valid_mean, label='Validation Accuracy', marker='o')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
